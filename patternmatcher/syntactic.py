# -*- coding: utf-8 -*-
from typing import Any, List, Type, Union, Iterator

from graphviz import Digraph

from patternmatcher.expressions import (Arity, Atom, Expression,
                                        Operation, Symbol, SymbolWildcard,
                                        Variable, Wildcard, freeze, Optional)


class _OperationEnd(object):
    """Represents the end of an operation expression in a :class:`Flatterm`.
    
    Used for :const:`OPERATION_END` as a singleton. Could also be a plain object,
    but the string representation is customized.
    """

    def __str__(self):
        return ')'

    __repr__ = __str__

OPERATION_END = _OperationEnd()
"""Constant used to represent the end of an operation in a :class:`Flatterm`.

This is a singleton object that has *)* as representation.
Is is also used by the :class:`DiscriminationNet`.
"""


def is_operation(term: Any) -> bool:
    """Return True iff the given term is a subclass of :class:`.Operation`."""
    return isinstance(term, type) and issubclass(term, Operation)


def is_symbol_wildcard(term: Any) -> bool:
    """Return True iff the given term is a subclass of :class:`.Symbol`."""
    return isinstance(term, type) and issubclass(term, Symbol)

# FlattermItemTypes = Union[Atom, Type[Operation], Type[Symbol], _OperationEnd]
FlattermItemTypes = Union[Atom, type, _OperationEnd]


class Flatterm(List[FlattermItemTypes]):
    """A flattened representation of an :class:`.Expression`.
    
    This is a subclass of list. This representation is similar to the prefix notation generated by
    :meth:`.Expression.preorder_iter`, but contains some additional elements.

    Operation expressions are represented by the :func:`type` of the operation before the operands as well as
    :const:`OPERATION_END` after the last operand of the operation:

    >>> Flatterm(f(a, b))
    [f, a, b, )]

    Variables are not included in the flatterm representation, only wildcards remain.

    >>> Flatterm(x_)
    [_]

    Consecutive wildcards are merged, as the :class:`DiscriminationNet` cannot handle multiple consecutive sequence
    wildcards:

    >>> Flatterm(f(_, _))
    [f, _[2], )]
    >>> Flatterm(f(_, __, __))
    [f, _[3+], )]

    Furthermore, every :class:`SymbolWildcard` is replaced by its :attr:`~SymbolWildcard.symbol_type`:

    >>> class SpecialSymbol(Symbol):
    ...     pass
    >>> Flatterm(Wildcard.symbol(SpecialSymbol))
    [<class '__main__.SpecialSymbol'>]

    Symbol wildcards are also not merged like regular wildcards, because they can never be sequence wildcards.
    """

    def __init__(self, expression: Expression) -> None:
        list.__init__(self, Flatterm._combined_wildcards_iter(Flatterm._flatterm_iter(expression)))

    @staticmethod
    def _flatterm_iter(expression: Expression) -> Iterator[FlattermItemTypes]:
        """Generator that yields the atoms of the expressions in prefix notation with operation end markers."""
        if isinstance(expression, Variable):
            yield from Flatterm._flatterm_iter(expression.expression)
        elif isinstance(expression, Operation):
            yield type(expression)
            for operand in expression.operands:
                yield from Flatterm._flatterm_iter(operand)
            yield OPERATION_END
        elif isinstance(expression, SymbolWildcard):
            yield expression.symbol_type
        elif isinstance(expression, Atom):
            yield expression
        else:
            raise TypeError()

    @staticmethod
    def _combined_wildcards_iter(flatterm: Iterator[FlattermItemTypes]) -> Iterator[FlattermItemTypes]:
        """Combines consecutive wildcards in a flatterm into a single one."""
        last_wildcard = None # type: Optional[Wildcard]
        for term in flatterm:
            if isinstance(term, Wildcard) and not isinstance(term, SymbolWildcard):
                if last_wildcard is not None:
                    last_wildcard = Wildcard(last_wildcard.min_count + term.min_count, last_wildcard.fixed_size and term.fixed_size)
                else:
                    last_wildcard = term
            else:
                if last_wildcard is not None:
                    yield last_wildcard
                    last_wildcard = None
                yield term
        if last_wildcard is not None:
            yield last_wildcard

    def _term_str(self, term: FlattermItemTypes) -> str:
        if is_operation(term):
            return term.name + '('
        elif is_symbol_wildcard(term):
            return '*%s' % term
        elif isinstance(term, Wildcard):
            return '*%s%s' % (term.min_count, (not term.fixed_size) and '+' or '')
        else:
            return str(term)

    def __str__(self):
        return ' '.join(map(self._term_str, self))

    def __repr__(self):
        return '[%s]' % ', '.join(map(str, self))

class _WildcardState:
    """Internal representation of the wildcard state at the current nesting level used by :class:`DiscriminationNet`.
    
    This state is needed because unless a sequence wildcard is the last operand of an operation, fallback edges are
    required.
    
    Consider the pattern ``f(___, a, b)``: In order to match for example ``f(a, c, a, b)``, the automaton for
    the pattern needs an edge to fall back to the sequence wildcard after reading the first ``a``, because the ``b`` is
    missing.

    The same applies when trying to match ``f(a, a, b)`` or ``f(a, b, a, b)``, but the position to fall back to is
    different. Hence, not only the :attr:`last_wildcard` is saved in the state, but also the :attr:`symbol_after` it.
    Also, :attr:`all_same` tracks whether all symbols of the pattern so far have been the same, so backtracking only
    jumps back to the most recent state. This is needed for patterns like ``f(___, a, a)`` and subjects like
    ``f(a, a, a)``.

    Things get more complicated, when nested operations are combined with sequence wildcards. For these, a failure state
    is generated and saved in :attr:`fail_state`. This state allows backtracking after a failed match in a nested operation.
    Consider the pattern ``f(___, g(a))`` and the subject ``f(g(b), g(a))`` which match. The automaton greedily
    steps into the nested operation ``g(b)`` instead of jumping over it with the wildcard. But after encountering the
    ``b``, it needs to backtrack to the wildcard and start looking for ``g(a)`` again. The failure state allows finishing
    to read the ``g(b)`` and start over.
    """

    def __init__(self):
        self.last_wildcard = None 
        """Last unbounded wildcard at the current level of operation nesting (if any)"""

        self.symbol_after = None 
        """Symbol after the last unbounded wildcard"""

        self.all_same = True        
        """True iff all symbols until now have been the same after the last unbounded wildcard"""

        self.fail_state = None
        """The failure state for the current level of operation nesting"""


class _StateQueueItem(object):
    """Internal data structure used by the product net algorithm.
    
    It contains a pair of states from each source net (:attr:`state1` and :attr:`state2`), their :attr:`ids <State.id>` or
    ``0`` if the state is ``None`` (:attr:`id1` and :attr:`id2`).

    It also keeps track of the operation nesting :attr:`depth` of the states. A state is
    uniquely identified by its state pair and depth. This is needed to combine patterns with
    varying nesting depths to distinguish between states that have the same states but different depth. While one of the
    original automatons uses a wildcard transition and the other an operation opening transition, the whole nested
    operation has to be processed.
    To track whether this process is complete, the :attr:`depth` is used.

    In addition, :attr:`fixed` tracks which of the two automata is using the wildcard transition. If it is set to ``1``,
    the first automaton is using it. If set to ``2``,  the second automaton is using it. Otherwise it will be set to
    ``0``. :attr:`fixed` can only be non-zero if the depth is greater than zero.
    """
    def __init__(self, state1, state2):
        self.state1 = state1
        self.state2 = state2
        try:
            self.id1 = state1.id
        except AttributeError:
            self.id1 = 0
        try:
            self.id2 = state2.id
        except AttributeError:
            self.id2 = 0
        self.depth = 0
        self.fixed = 0

    @property
    def keys(self):
        """Return the set of transitions to examine for this queue state.
        
        This is the union of the transition sets for both states.
        However, if one of the states is fixed, it is excluded from this union and a wildcard transition is included
        instead. Also, when already in a failed state (one of the states is ``None``), the :const:`OPERATION_END` is also
        included.
        """
        keys = set()
        if self.state1 is not None and self.fixed != 1:
            keys.update(self.state1.keys())
        if self.state2 is not None and self.fixed != 2:
            keys.update(self.state2.keys())
        if self.fixed != 0:
            if self.fixed == 1 and self.state2 is None:
                keys.add(OPERATION_END)
            elif self.fixed == 2 and self.state1 is None:
                keys.add(OPERATION_END)
            keys.add(Wildcard)
        return keys

    def __repr__(self):
        return 'NQI(%r, %r, %r, %r, %r, %r)' % (self.id1, self.id2, self.depth, self.fixed, self.state1, self.state2)

class _State(dict):
    _id = 1

    def __init__(self):
        super().__init__(self)
        self.id = _State._id
        _State._id += 1

    def _term_str(self, term):
        if is_operation(term):
            return term.name + '('
        elif is_symbol_wildcard(term):
            return '*%s' % term
        elif term == Wildcard:
            return '*'
        else:
            return str(term)

    def _val_str(self, value):
        if value is self:
            return 'self'
        elif isinstance(value, list):
            return repr(list(map(str, value)))
        else:
            return str(value)

    def __repr__(self):
        return '{STATE %s}' % (', '.join('%s:%s' % (self._term_str(k), self._val_str(v)) for k, v in self.items()))

class DiscriminationNet(object):
    def __init__(self):
        self._net = _State()

    def add(self, pattern):
        net = DiscriminationNet._generate_net(pattern)
        self._net = DiscriminationNet._product_net(self._net, net)

    @staticmethod
    def _build_fail_states(state: _State, wildcard_states: List[_WildcardState]) -> None:
        """Generates a chain of fail states from the given state back to the first fail state or sequence wildcard up in
        the operation tree.
        
        These fail states are self looping with wildcard transitions and transition to one another with
        :const:`OPERATION_END` transitions. They provide a way to backtrack out of nested operations after a failure
        back to the last sequence wildcard.
        """
        for last_state in reversed(wildcard_states[:-1]):
            state[OPERATION_END] = last_state.last_wildcard or last_state.fail_state or _State()
            if last_state.fail_state is not None or last_state.last_wildcard is not None:
                break
            last_state.fail_state = state = state[OPERATION_END]
            state[Wildcard] = state

    @staticmethod
    def _generate_net(pattern):
        """Generates a DFA matching the given pattern."""
        last_state = None
        last_term = None
        # Capture the last unbounded wildcard for every level of operation nesting on a stack
        # Used to add backtracking edges in case the "match" fails later
        wildcard_states = [_WildcardState()]
        root = state = _State()
        flatterm = Flatterm(pattern)

        for j, term in enumerate(flatterm):
            last_state = state
            last_term = term
            wc_state = wildcard_states[-1]
            # For wildcards, generate a chain of #min_count Wildcard edges
            # If the wildcard is unbounded (fixed_size = False),
            # add a wildcard self loop at the end
            if isinstance(term, Wildcard):
                last_term = Wildcard
                for _ in range(term.min_count):
                    state[Wildcard] = _State()
                    state = state[Wildcard]
                if not term.fixed_size:
                    state[Wildcard] = state
                    # set wildcard state to this reference this wildcard
                    wc_state.last_wildcard = state
                    wc_state.symbol_after = None
                    wc_state.all_same = True
                # Add backtracking edge for ')' if there was an unbounded wildcard on a higher level
                if any(s.last_wildcard is not None for s in wildcard_states[:-1]):
                    try:
                        if flatterm[j+1] != OPERATION_END:
                            DiscriminationNet._build_fail_states(state, wildcard_states)
                    except IndexError:
                        pass
            else:
                state[term] = _State()
                state = state[term]
                if wc_state.symbol_after is None:
                    wc_state.symbol_after = term
                if term != wc_state.symbol_after:
                    wc_state.all_same = False
                if is_operation(term):
                    wildcard_states.append(_WildcardState())
                if term == OPERATION_END:
                    wildcard_states.pop()

                wc_state = wildcard_states[-1]
                try:
                    next_term = flatterm[j+1]
                except IndexError:
                    next_term = None

                # Potentially, backtracking wildcard edges have to be added
                if next_term is not None and not isinstance(next_term, Wildcard):
                    # If there was an unbounded wildcard inside the current operation,
                    # add a backtracking wildcard edge to it
                    if wc_state.last_wildcard is not None:
                        state[Wildcard] = wc_state.last_wildcard
                        # Also add an edge for the symbol directly after the wildcard to
                        # its respecitive state (or as a self loop if all symbols are the same)
                        if next_term != wc_state.symbol_after:
                            if wc_state.all_same and next_term == OPERATION_END and not is_operation(wc_state.symbol_after):
                                state[wc_state.symbol_after] = state
                            else:
                                state[wc_state.symbol_after] = wc_state.last_wildcard[wc_state.symbol_after]
                    # If there was an unbounded wildcard inside a parent operation of the current one,
                    # an additional fail state is needed, that eventually backtracks to the wildcard
                    # Every level of operation nesting gets its own fail state until the level of the
                    # wildcard is reached
                    elif any(s.last_wildcard is not None for s in wildcard_states):
                        if wc_state.fail_state is None:
                            wc_state.fail_state = _State()
                            wc_state.fail_state[Wildcard] = wc_state.fail_state
                            DiscriminationNet._build_fail_states(wc_state.fail_state, wildcard_states)
                        state[Wildcard] = wc_state.fail_state
                        if next_term != OPERATION_END:
                            state[OPERATION_END] = wc_state.fail_state[OPERATION_END]

        last_state[last_term] = [pattern]

        return root

    @staticmethod
    def _product_net(state1, state2):
        def get_child(state, key, fixed):
            if fixed:
                return state, False
            if state is not None:
                try:
                    try:
                        return state[key], False
                    except KeyError:
                        if key == OPERATION_END:
                            return None, False
                        if isinstance(key, Symbol):
                            try:
                                symbol_wildcard_key = next(t for t in state.keys() if is_symbol_wildcard(t) and isinstance(key, t))
                                return state[symbol_wildcard_key], False 
                            except StopIteration:
                                pass
                        return state[Wildcard], True
                except KeyError:
                    return None, False
            return None, False

        root = _State()
        states = {(state1.id, state2.id, 0): root}
        queue = [_StateQueueItem(state1, state2)]

        while len(queue) > 0:
            current_state = queue.pop(0)
            state = states[(current_state.id1, current_state.id2, current_state.depth)]

            for k in list(current_state.keys):
                t1, with_wildcard1 = get_child(current_state.state1, k, current_state.fixed == 1)
                t2, with_wildcard2 = get_child(current_state.state2, k, current_state.fixed == 2)

                child_state = _StateQueueItem(t1, t2)
                child_state.depth = current_state.depth
                child_state.fixed = current_state.fixed

                if is_operation(k):
                    if current_state.fixed:
                        child_state.depth += 1
                    elif with_wildcard1:
                        child_state.fixed = 1
                        child_state.depth = 1
                        child_state.state1 = current_state.state1
                        child_state.id1 = current_state.id1
                    elif with_wildcard2:
                        child_state.fixed = 2
                        child_state.depth = 1
                        child_state.state2 = current_state.state2
                        child_state.id2 = current_state.id2
                elif k == OPERATION_END and current_state.fixed:
                    child_state.depth -= 1

                    if child_state.depth == 0:
                        if child_state.fixed == 1:
                            child_state.state1 = child_state.state1[Wildcard]
                            try:
                                child_state.id1 = child_state.state1.id
                            except AttributeError:
                                child_state.id1 = 0
                        elif child_state.fixed == 2:
                            child_state.state2 = child_state.state2[Wildcard]
                            try:
                                child_state.id2 = child_state.state2.id
                            except AttributeError:
                                child_state.id2 = 0
                        else:
                            assert False # unreachable
                        child_state.fixed = 0

                if child_state.id1 != 0 or child_state.id2 != 0:
                    if (child_state.id1, child_state.id2, child_state.depth) not in states:
                        states[(child_state.id1, child_state.id2, child_state.depth)] = _State()
                        queue.append(child_state)

                    state[k] = states[(child_state.id1, child_state.id2, child_state.depth)]
                else:
                    if isinstance(child_state.state1, list) and isinstance(child_state.state2, list):
                        state[k] = child_state.state1 + child_state.state2
                    elif isinstance(child_state.state1, list):
                        state[k] = child_state.state1
                    elif isinstance(child_state.state2, list):
                        state[k] = child_state.state2

        return root

    def match(self, expression):
        state = self._net
        depth = 0
        for term in Flatterm(expression):
            if depth > 0:
                if is_operation(term):
                    depth += 1
                elif term == OPERATION_END:
                    depth -= 1
            else:
                try:
                    try:
                        state = state[term]
                    except KeyError:
                        if is_operation(term):
                            depth = 1
                        elif term == OPERATION_END:
                            return []
                        elif isinstance(term, Symbol):
                            try:
                                symbol_wildcard_key = next(t for t in state.keys() if is_symbol_wildcard(t) and isinstance(term, t))
                                state =  state[symbol_wildcard_key] 
                            except StopIteration:
                                state = state[Wildcard]
                        else:
                            state = state[Wildcard]
                except KeyError:
                    return []

                if isinstance(state, list):
                    return state

        assert isinstance(state, list)
        return state

    def _term_str(self, term):
        if is_operation(term):
            return term.name + '('
        elif is_symbol_wildcard(term):
            return '*%s' % term.__name__
        elif term == Wildcard:
            return '*'
        else:
            return str(term)

    def as_graph(self):
        dot = Digraph()

        nodes = set()
        queue = [self._net]
        while queue:
            state = queue.pop(0)
            nodes.add(state.id)
            dot.node('n%s' % state.id, '', {'shape': 'point'})

            for next_state in state.values():
                if isinstance(next_state, _State):
                    if next_state.id not in nodes:
                        queue.append(next_state)
                else:
                    l = '\n'.join(str(x) for x in next_state)
                    dot.node('l%s' % id(next_state), l, {'shape': 'plaintext'})

        nodes = set()
        queue = [self._net]
        while queue:
            state = queue.pop(0)
            if state.id in nodes:
                continue
            nodes.add(state.id)

            for (label, other) in state.items():
                if isinstance(other, _State):
                    dot.edge('n%s' % state.id, 'n%s' % other.id, self._term_str(label))
                    if other.id not in nodes:
                        queue.append(other)
                else:
                    dot.edge('n%s' % state.id, 'l%s' % id(other), self._term_str(label))

        return dot

def _test_times_with_types(): # pragma: no cover
    Times = Operation.new('Times', Arity.variadic, 'Times', one_identity=True)
    Inverse = Operation.new('Inv', Arity.unary, 'Inverse')
    InverseTranspose = Operation.new('InvT', Arity.unary, 'InverseTranspose')
    Transpose = Operation.new('T', Arity.unary, 'Transpose')

    class Scalar(Symbol):
        pass

    class Matrix(Symbol):
        pass

    class Vector(Symbol):
        pass

    scalar = Wildcard.symbol(Scalar)
    vector = Wildcard.symbol(Vector)
    matrix = Wildcard.symbol(Matrix)

    patterns = [
        Times(Inverse(matrix), matrix),
        Times(Inverse(matrix), Transpose(matrix)),
        Times(Inverse(matrix), vector),
        Times(Inverse(scalar), matrix),
        Times(InverseTranspose(matrix), matrix),
        Times(InverseTranspose(matrix), Transpose(matrix)),
        Times(InverseTranspose(matrix), vector),
        Times(matrix, Inverse(matrix)),
        Times(matrix, InverseTranspose(matrix)),
        Times(matrix, matrix),
        Times(matrix, Transpose(matrix)),
        Times(matrix, vector),
        Times(scalar, matrix),
        Times(scalar, scalar),
        Times(scalar, vector),
        Times(Transpose(matrix), Inverse(matrix)),
        Times(Transpose(matrix), InverseTranspose(matrix)),
        Times(Transpose(matrix), matrix),
        Times(Transpose(matrix), Transpose(matrix)),
        Times(Transpose(matrix), vector),
        Times(Transpose(vector), Inverse(matrix)),
        Times(Transpose(vector), InverseTranspose(matrix)),
        Times(Transpose(vector), matrix),
        Times(Transpose(vector), Transpose(matrix)),
        Times(Transpose(vector), vector),
        Times(vector, Transpose(vector)),
    ]

    net = DiscriminationNet()
    for pattern in map(freeze, patterns):
        net.add(pattern)

    net.as_graph().render()

def _random_test(count): # pragma: no cover
    f = Operation.new('f', arity=Arity.binary)
    g = Operation.new('g', arity=Arity.unary)
    a = Symbol('a')
    b = Symbol('b')
    c = Symbol('c')
    x = Variable.dot('x')

    import hypothesis.strategies as st

    def func_wrap_strategy(args, func):
        min_size = func.arity[0]
        max_size = func.arity[1] and func.arity[0] or 4
        return st.lists(args, min_size=min_size, max_size=max_size).map(lambda a: func(*a))

    ExpressionBaseStrategy = st.sampled_from([a, b, c, x])
    ExpressionRecurseStrategy = lambda args: func_wrap_strategy(args, f) | func_wrap_strategy(args, g)
    ExpressionStrategy = st.recursive(ExpressionBaseStrategy, ExpressionRecurseStrategy, max_leaves=10)

    net = DiscriminationNet()
    exprs = set(freeze(ExpressionStrategy.example()) for _ in range(count))
    for expr in exprs:
        net.add(expr)

    graph = net.as_graph()

    graph.render()

if __name__ == '__main__':
    import doctest

    f = Operation.new('f', Arity.variadic)
    a = Symbol('a')
    b = Symbol('b')
    c = Symbol('c')
    x_ = Variable.dot('x')
    _ = Wildcard.dot()
    __ = Wildcard.plus()

    doctest.testmod(exclude_empty=True)
